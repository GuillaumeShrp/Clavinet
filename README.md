Modified version for MSc research project use at Keio University.

# When Music Meets A.I. 
[Paper](https://ieeexplore.ieee.org/abstract/document/9302731) | [Music Samples (.mp3)](https://bit.ly/3b5QYKW) | [Supplementary Report](https://drive.google.com/file/d/1gV5LNfdKqRvXVQ3fTstOMq3qWrcmxNyg/view?usp=sharing)

### Official TF implementation of the paper: "Style-conditioned Music Generation"

#### IEEE Multimedia Magazine 2021 | ICME 2020 (oral)

## Description
This is a joint work with the Department of Music (University of Malaya). It presents a refinement to the vanilla formulation of Variational Auto-Encoder (VAE) which allow users to condition the compositional style of music generated by the model. In our experiments, we trained our model on Bach chorales (JSB) and western folk tunes (NMD). At generation time, users can specify the model to generate music in the style of Bach or folk tunes. The datasets used in the experiment can be downloaded at [POP](http://www.ambrosepianotabs.com/page/library?pg=1), [JSB](http://kern.humdrum.org/search?s=t&keyword=Bach%20Johann&fbclid=IwAR39fsc8gUWjN6eYAUkewldNkeV499lX0Ew6VP8Nrrd_T1T7plaIIIb5nFQ) and [NMD](http://www-etud.iro.umontreal.ca/~boulanni/icml2012).


## License and Copyright
This project is open source under the BSD-3 license (see [`LICENSE`](./LICENSE)). Codes can be used freely only for academic purpose.

For commercial purpose usage, please contact Dr. Chee Seng Chan at `cs.chan at um.edu.my`

&#169;2020 Center of Image and Signal Processing, Faculty of Computer Science and Information Technology, University of Malaya.
